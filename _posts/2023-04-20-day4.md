---
title: "Setting up BLIP-2 model locally using int8 precision on local machines"
date: "2023-04-20"
updated: "2023-04-20"
author: juellsprott
tags:
  - thesis, blip-2

---



First attempt at running the model with [int8 precision](https://github.com/salesforce/LAVIS/tree/main/projects/blip2) on a workstation in the LAB42 Robolab results in various CUDA-related errors, likely indicating incorrect libraries or modules installed. 

After testing on various machines and some module and library troubleshooting, the model using int8 precision can be run on:
- My home PC, running a 980 TI, Ryzen 5 3600 with 16 GB RAM with Windows 11 Education
  - This requires the use of a [seperately compiled version](https://github.com/acpopescu/bitsandbytes/releases/) of bitsandbytes for Windows, as the most recent version from the official bitsandbytes repository doesn't come compiled with GPU support:
  ```
  pip install https://github.com/acpopescu/bitsandbytes/releases/download/v0.37.2-win.1/bitsandbytes-0.37.2-py3-none-any.whl
  ```
  
- The workstations in LAB42 Robolab, running RTX 1000-3000 series GPUs and 64 GB RAM, Ubuntu 22.04
The model cannot be run on:
- My latop, running integrated GPU and Intel Core i7 Processor, even with the model ran on CPU
- Google Colab, as the RAM available for free is 12 GB, which is (presumably) insufficient (estimated RAM usage when loading shards with int8 precision: ~12-16 GB)

Only attempted to run model on test image so far, model will be run on the NOUN dataset on a later date.
