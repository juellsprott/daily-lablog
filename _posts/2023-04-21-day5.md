---
title: "Setting up BLIP-2 and NOUN pipeline notebook"
date: "2023-04-21"
updated: "2023-04-21"
author: juellsprott
tags:
  - thesis, blip-2, noun, torch

---



Worked on setting up a pipeline used for loading the model and captioning all non categorized objects in the NOUN-2-600DPI folder of the dataset. 

The model is loaded as follows (using int8 precision): 
```
# load processor
processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")

# load in float16 # load in int8
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b",
                                                      load_in_8bit=True, device_map="auto")
# setup device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

Which downloads the 15 GB model using two seperate 'shards' (One 10 GB, the other 5 GB). and loads them into memory. During loading, RAM usage can spike up to ~15 GB, and if no GPU with sufficient VRAM is available, this will cause a kernel crash. After loading this model on my own PC at home, RAM usage drops upon successful model load and the model can be used for inference.

Following this, the dataset previously created using only non-categorized images is used to perform inference:
